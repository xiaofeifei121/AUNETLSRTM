{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab233cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as sp\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import deepwave\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from deepinvhessian import fwi\n",
    "from deepinvhessian.utilities import *\n",
    "from deepinvhessian.filters import *\n",
    "from deepinvhessian.train import *\n",
    "from deepinvhessian.masks import *\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(14)\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f9ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(directory):\n",
    "    \"\"\"\n",
    "    Creates the given directory if it does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory\n",
    "\n",
    "def clear_dir(directory):\n",
    "    \"\"\"\n",
    "    Removes all files in the given directory.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory): raise Exception(\"%s is not a directory\"%(directory))\n",
    "    if type(directory) != str: raise Exception(\"string type required for directory: %s\"%(directory))\n",
    "    if directory in [\"..\",\".\", \"\",\"/\",\"./\",\"../\",\"*\"]: raise Exception(\"trying to delete current directory, probably bad idea?!\")\n",
    "    \n",
    "    for f in os.listdir(directory):\n",
    "        path = os.path.join(directory, f)\n",
    "        try:\n",
    "            if os.path.isfile(path):\n",
    "                os.remove(path)\n",
    "            elif os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70dcfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and acquisition parameters\n",
    "par = {'nx':601,   'dx':0.01, 'ox':0,\n",
    "       'nz':221,   'dz':0.01, 'oz':0,\n",
    "        'num_shots':30,    'ds':0.2,   'os':0,  'sz':0,\n",
    "       'num_receivers_per_shot':300,   'dr':0.02,  'orec':0, 'rz':0,\n",
    "       'nt':4000,  'dt':0.001,  'ot':0,\n",
    "       'freq': 20, 'num_sources_per_shot':1, 'num_dims':2,\n",
    "       'num_batches':30,\n",
    "        'FWI_itr': 100\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = './Exp_Marmousi_bb/'\n",
    "type='bb'\n",
    "velocity_model=\"Marmousi\"\n",
    "seismic_path = exp_name + \"seismic_data/\"\n",
    "get_dir(seismic_path)\n",
    "obs_dir = seismic_path + f\"shot_{velocity_model}_born_big\" \n",
    "\n",
    "output_path = exp_name + f\"velocity_{type}/\"\n",
    "get_dir(output_path)\n",
    "model_dir = output_path + f\"velocity_{velocity_model}\"\n",
    "\n",
    "vel_path =\"../data/\"\n",
    "vel_dir  = vel_path + \"Marm.bin\"\n",
    "\n",
    "print(\"obs_dir:\", obs_dir)\n",
    "print(\"vel_dir:\", vel_dir)\n",
    "print(\"model_dir:\", model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true model\n",
    "model_true = (np.fromfile(vel_dir, np.float32)\n",
    "              .reshape(par['nz'], par['nx']))\n",
    "model_init = sp.ndimage.gaussian_filter(model_true, sigma=[2,2])\n",
    "\n",
    "model_sclar= (model_true - model_init)/model_true\n",
    "\n",
    "data_true = (\n",
    "    torch.from_file(obs_dir,\n",
    "                    size=par['num_shots']*par['num_receivers_per_shot']*par['nt'])\n",
    "    .reshape(par['num_shots'], par['num_receivers_per_shot'], par['nt'])\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26911581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get water layer mask\n",
    "def mask(model,value):\n",
    "    \"\"\"\n",
    "    Return a mask for the model (m) using the (value)\n",
    "    \"\"\"\n",
    "    mask = model > value\n",
    "    mask = mask.astype(int)\n",
    "    mask[:21] = 0\n",
    "    return mask\n",
    "\n",
    "mask = mask(model_true, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83773428",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vmin, v_vmax = np.percentile(model_true, [2,98]) \n",
    "m_vmin, m_vmax = np.percentile(model_sclar, [2,98]) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 model_true 和 model_pred 都是 numpy 数组\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 第一个子图：model_true\n",
    "im1 = ax[0].imshow(model_true, cmap='jet', vmin=v_vmin, vmax=v_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[0].set_title('Marmousi true model')\n",
    "fig.colorbar(im1, ax=ax[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# 第二个子图：model_pred （如果你有另一个模型）\n",
    "im2 = ax[1].imshow(model_sclar, cmap='jet', vmin=m_vmin, vmax=m_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[1].set_title('Predicted model')\n",
    "fig.colorbar(im2, ax=ax[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "vpmin, vpmax = torch.quantile(data_true[par['num_shots']//2], torch.tensor([0.01, 0.99]).to(device))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(data_true[par['num_shots']//2].cpu().detach().numpy().T, aspect='auto', cmap='gray', vmin=vpmin, vmax=vpmax)\n",
    "plt.xlabel(\"Receiver\")\n",
    "plt.ylabel(\"Time sample\")\n",
    "plt.title(\"Observed VX\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7731af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the source the wavelet\n",
    "source_wavelet = deepwave.wavelets.ricker(par['freq'], par['nt'], par['dt'], 1/par['freq'])\n",
    "# Initialize the FWI class\n",
    "params = fwi.FWIParams(par, torch.tensor(source_wavelet), 1)\n",
    "# Get the source receiver coordinates\n",
    "x_s1, x_r1 = params.get_coordinate(1)\n",
    "# Create a wavelet for every source\n",
    "source_amplitudes = params.create_wavelet(torch.tensor(source_wavelet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the source wavelet\n",
    "plt.plot(np.arange(0,par['nt'])*par['dt'], source_amplitudes[0,0,:])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('Source wavelet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe384c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run conventional FWI with the Barzilai-Borwein method\n",
    "scatter = torch.zeros_like(torch.tensor(model_true).float())\n",
    "model_velocity = torch.tensor(model_true)\n",
    "# Move data to GPU if using GPU\n",
    "model = torch.tensor(scatter).clone().to(device)\n",
    "model.requires_grad = True\n",
    "data_true = torch.tensor(data_true).float()\n",
    "mask = torch.tensor(mask).to(device)\n",
    "# Create lists to save results\n",
    "gradients, updates, fwi_loss, ssim_list, alphas = [], [], [], [], []\n",
    "\n",
    "data_range = model_sclar.max() - model_sclar.min()\n",
    "loss_fn = nn.MSELoss() # Misfit function for FWI\n",
    "optimizer = torch.optim.SGD([{'params': [model], 'lr': 1e-1,}]) # Optimizer to run FWI with step size: lr\n",
    "tsamples = 0 # Number of time samples starting from zero to exclude from computing the misfit\n",
    "FWI_iter = 100 # Number of FWI iterations\n",
    "\n",
    "t_start = time.time()\n",
    "for iteration in tqdm(range(FWI_iter)):\n",
    "    # Compute the structural similarity index measure (ssim) between the current and the true models\n",
    "    ssim_metric = ssim(model.detach().cpu().numpy(), model_sclar, data_range=data_range)\n",
    "    ssim_list.append(ssim_metric)\n",
    "    # Compute FWI gradient\n",
    "    optimizer.zero_grad()\n",
    "    grad, iter_loss = fwi.compute_gradient_born(params, model_velocity, model, data_true, loss_fn, tsamples, device)\n",
    "    fwi_loss.append(iter_loss)\n",
    "    print(f'FWI iteration: {iteration} loss = {fwi_loss[-1]}, ssim = {ssim_list[-1]}')\n",
    "    # Clip the gradient values\n",
    "    torch.nn.utils.clip_grad_value_(model, torch.quantile(grad.detach().abs(), 0.98))\n",
    "\n",
    "    if iteration == 0: gmax0 =  torch.abs(grad.detach()).max()\n",
    "    # Normalize the gradient, mask it around the sources\n",
    "    grad = (grad /gmax0) * mask\n",
    "    gradients.append(grad.cpu().detach().numpy())\n",
    "    # Calculate the step size\n",
    "    # if iteration > 0:\n",
    "    #     delta_model = model.detach().clone() - previous_model\n",
    "    #     delta_grad = grad.detach().clone() - previous_grad\n",
    "    #     alpha = fwi.bb_step(delta_model, delta_grad, 'short')\n",
    "    #     alphas.append(alpha)\n",
    "    #     optimizer.param_groups[-1]['lr'] = alpha\n",
    "    # # Save the current solution and gradient for calculating the step size in the next iteration\n",
    "    # previous_model = model.detach().clone()\n",
    "    # previous_grad = grad.detach().clone()\n",
    "    # Update the model\n",
    "    model.grad.data[:] = grad\n",
    "    optimizer.step()\n",
    "    updates.append(model.detach().clone().cpu().numpy())\n",
    "    # Plot the results\n",
    "    if iteration % 20 == 0:\n",
    "        show_one_iter_fwi(grad.cpu(), model.detach().cpu(), iteration=iteration,\n",
    "                    cmap='gray', vmin=m_vmin, vmax=m_vmax, extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0), save_path=f'{exp_name}')\n",
    "t_end = time.time()\n",
    "t_delta = t_end - t_start\n",
    "print(f'Runtime:{datetime.timedelta(seconds=t_delta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef163da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu().detach().numpy().T.tofile(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vmin, v_vmax = np.percentile(model.cpu().detach().numpy(), [2,98]) \n",
    "m_vmin, m_vmax = np.percentile(model_sclar, [2,98]) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 model_true 和 model_pred 都是 numpy 数组\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 第一个子图：model_true\n",
    "im1 = ax[0].imshow(model.cpu().detach().numpy(), cmap='gray', vmin=m_vmin, vmax=m_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[0].set_title('Marmousi true model')\n",
    "fig.colorbar(im1, ax=ax[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# 第二个子图：model_pred （如果你有另一个模型）\n",
    "im2 = ax[1].imshow(model_sclar, cmap='gray', vmin=m_vmin, vmax=m_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[1].set_title('Predicted model')\n",
    "fig.colorbar(im2, ax=ax[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "vpmin, vpmax = torch.quantile(data_true[par['num_shots']//2], torch.tensor([0.01, 0.99]).to(device))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(data_true[par['num_shots']//2].cpu().detach().numpy().T, aspect='auto', cmap='gray', vmin=vpmin, vmax=vpmax)\n",
    "plt.xlabel(\"Receiver\")\n",
    "plt.ylabel(\"Time sample\")\n",
    "plt.title(\"Observed VX\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{output_path}/losses', fwi_loss=np.array(fwi_loss),\n",
    "                               ssim=np.array(ssim_list),\n",
    "                               )\n",
    "np.savez(f'{output_path}/results', updates=np.array(updates), \n",
    "                            gradients=np.array(gradients), \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5fd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepinvhessian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
