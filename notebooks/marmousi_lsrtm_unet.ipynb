{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as sp\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import deepwave\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from deepinvhessian import fwi\n",
    "from deepinvhessian.utilities import *\n",
    "from deepinvhessian.filters import *\n",
    "from deepinvhessian.train import *\n",
    "from deepinvhessian.masks import *\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(14)\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(directory):\n",
    "    \"\"\"\n",
    "    Creates the given directory if it does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory\n",
    "\n",
    "def clear_dir(directory):\n",
    "    \"\"\"\n",
    "    Removes all files in the given directory.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory): raise Exception(\"%s is not a directory\"%(directory))\n",
    "    if type(directory) != str: raise Exception(\"string type required for directory: %s\"%(directory))\n",
    "    if directory in [\"..\",\".\", \"\",\"/\",\"./\",\"../\",\"*\"]: raise Exception(\"trying to delete current directory, probably bad idea?!\")\n",
    "    \n",
    "    for f in os.listdir(directory):\n",
    "        path = os.path.join(directory, f)\n",
    "        try:\n",
    "            if os.path.isfile(path):\n",
    "                os.remove(path)\n",
    "            elif os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and acquisition parameters\n",
    "par = {'nx':601,   'dx':0.01, 'ox':0,\n",
    "       'nz':221,   'dz':0.01, 'oz':0,\n",
    "        'num_shots':30,    'ds':0.2,   'os':0,  'sz':0,\n",
    "       'num_receivers_per_shot':300,   'dr':0.02,  'orec':0, 'rz':0,\n",
    "       'nt':4000,  'dt':0.001,  'ot':0,\n",
    "       'freq': 20, 'num_sources_per_shot':1, 'num_dims':2,\n",
    "       'num_batches':30,\n",
    "        'FWI_itr': 100\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = './Exp_Marmousi_Unet_dm/'\n",
    "type='UNet'\n",
    "velocity_model=\"Marmousi\"\n",
    "seismic_path = exp_name + \"seismic_data/\"\n",
    "get_dir(seismic_path)\n",
    "obs_dir = seismic_path + f\"shot_{velocity_model}_born_big\" \n",
    "\n",
    "output_path = exp_name + f\"velocity_{type}/\"\n",
    "get_dir(output_path)\n",
    "model_dir = output_path + f\"velocity_{velocity_model}\"\n",
    "\n",
    "vel_path =\"../data/\"\n",
    "vel_dir  = vel_path + \"Marm.bin\"\n",
    "\n",
    "print(\"obs_dir:\", obs_dir)\n",
    "print(\"vel_dir:\", vel_dir)\n",
    "print(\"model_dir:\", model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true model\n",
    "model_true = (np.fromfile(vel_dir, np.float32)\n",
    "              .reshape(par['nz'], par['nx']))\n",
    "\n",
    "\n",
    "data_true = (\n",
    "    torch.from_file(obs_dir,\n",
    "                    size=par['num_shots']*par['num_receivers_per_shot']*par['nt'])\n",
    "    .reshape(par['num_shots'], par['num_receivers_per_shot'], par['nt'])\n",
    ").to(device)\n",
    "\n",
    "# function to get water layer mask\n",
    "\n",
    "# Load the true model\n",
    "model_true = (np.fromfile(vel_dir, np.float32)\n",
    "              .reshape(par['nz'], par['nx']))\n",
    "model_init = sp.ndimage.gaussian_filter(model_true, sigma=[2,2])\n",
    "\n",
    "model_sclar= (model_true - model_init)/model_true\n",
    "\n",
    "data_true = (\n",
    "    torch.from_file(obs_dir,\n",
    "                    size=par['num_shots']*par['num_receivers_per_shot']*par['nt'])\n",
    "    .reshape(par['num_shots'], par['num_receivers_per_shot'], par['nt'])\n",
    ").to(device)\n",
    "\n",
    "def mask(model,value):\n",
    "    \"\"\"\n",
    "    Return a mask for the model (m) using the (value)\n",
    "    \"\"\"\n",
    "    mask = model > value\n",
    "    mask = mask.astype(int)\n",
    "    mask[:21] = 0\n",
    "    return mask\n",
    "\n",
    "mask = mask(model_true, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vmin, v_vmax = np.percentile(model_true, [2,98]) \n",
    "m_vmin, m_vmax = np.percentile(model_sclar, [2,98]) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 model_true 和 model_pred 都是 numpy 数组\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 第一个子图：model_true\n",
    "im1 = ax[0].imshow(model_true, cmap='jet', vmin=v_vmin, vmax=v_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[0].set_title('Marmousi true model')\n",
    "fig.colorbar(im1, ax=ax[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# 第二个子图：model_pred （如果你有另一个模型）\n",
    "im2 = ax[1].imshow(model_sclar, cmap='jet', vmin=m_vmin, vmax=m_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[1].set_title('Predicted model')\n",
    "fig.colorbar(im2, ax=ax[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "vpmin, vpmax = torch.quantile(data_true[par['num_shots']//2], torch.tensor([0.01, 0.99]).to(device))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(data_true[par['num_shots']//2].cpu().detach().numpy().T, aspect='auto', cmap='gray', vmin=vpmin, vmax=vpmax)\n",
    "plt.xlabel(\"Receiver\")\n",
    "plt.ylabel(\"Time sample\")\n",
    "plt.title(\"Observed VX\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the source the wavelet\n",
    "source_wavelet = deepwave.wavelets.ricker(par['freq'], par['nt'], par['dt'], 1/par['freq'])\n",
    "# Initialize the FWI class\n",
    "params = fwi.FWIParams(par, torch.tensor(source_wavelet), 1)\n",
    "# Get the source receiver coordinates\n",
    "x_s1, x_r1 = params.get_coordinate(1)\n",
    "# Create a wavelet for every source\n",
    "source_amplitudes = params.create_wavelet(torch.tensor(source_wavelet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run FWI with the proposed approach $\\delta m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute source illumination\n",
    "# device = 'cpu'\n",
    "# SI = fwi.source_illumination(torch.tensor(model_init), source_amplitudes, par['dx'], par['dt'], x_s1, device=device)\n",
    "# # clear memory\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# # Visualize the source illumination\n",
    "# simin, simax = np.percentile(SI.cpu(), [2,98])\n",
    "# show_model(SI.cpu(), cmap='bwr', vmin=simin, vmax=simax, figsize=(12, 5), extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0),\n",
    "#            title='Source Illumination')\n",
    "# np.savez(f'{output_path}/source_illumination', si=SI.detach().clone().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f'{output_path}/source_illumination.npz')\n",
    "\n",
    "# # 提取其中的 'si' 数组\n",
    "si_array = data['si']\n",
    "\n",
    "# # 转换为 PyTorch 张量，并移动到 CPU\n",
    "SI = torch.tensor(si_array, device=device)\n",
    "simin, simax = np.percentile(SI.cpu(), [2,98])\n",
    "show_model(SI.cpu(), cmap='bwr', vmin=simin, vmax=simax, figsize=(8, 5), \n",
    "           title='Source Illumination')\n",
    "SI = torch.tensor(SI).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FWI with the proposed method\n",
    "scatter = torch.zeros_like(torch.tensor(model_true).float())\n",
    "model_velocity = torch.tensor(model_true)\n",
    "# Move data to GPU if using GPU\n",
    "model = torch.tensor(scatter).clone().to(device)\n",
    "model.requires_grad = True\n",
    "data_true = torch.tensor(data_true).float()\n",
    "mask = torch.tensor(mask).to(device)\n",
    "# Create lists to save results\n",
    "gradients, dm1s, gradients_pred, dms, updates, fwi_loss, ssim_list, network_loss, alphas = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "data_range = model_sclar.max() - model_sclar.min()\n",
    "loss_fn = torch.nn.MSELoss() # Misfit function for FWI and Born modelling\n",
    "optimizer = torch.optim.SGD([{'params': [model], 'lr': 1e-2}]) # Optimizer to run FWI with step size: lr\n",
    "# Create the network, its optimizer and the loss function to train it\n",
    "network = UNet(n_channels=1, n_classes=1, hidden_channels=256).to(device)\n",
    "optimizer_unet = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "l2_norm = torch.nn.MSELoss()\n",
    "network_iter_init =1000 # Number of epochs to train the network in the first FWI iteration\n",
    "network_iter_fin = 300 # Number of epochs to train the network in every FWI iteration except the first one\n",
    "tsamples = 0 # Number of time samples starting from zero to exclude from computing the misfit\n",
    "FWI_iter = 100 # Number of FWI iterations\n",
    "t_start = time.time()\n",
    "for iteration in tqdm(range(FWI_iter)):\n",
    "    # Compute the structural similarity index measure (ssim) between the current and the true models\n",
    "    ssim_metric = ssim(model.detach().cpu().numpy(), model_sclar, data_range=data_range)\n",
    "    ssim_list.append(ssim_metric)\n",
    "    # Compute FWI gradient\n",
    "    optimizer.zero_grad()\n",
    "    grad, iter_loss = fwi.compute_gradient_born(params, model_velocity, model, data_true, loss_fn, tsamples, device)\n",
    "    fwi_loss.append(iter_loss)\n",
    "    print(f'FWI iteration: {iteration} loss = {fwi_loss[-1]}, ssim = {ssim_list[-1]}')\n",
    "    # Clip the gradient values\n",
    "    torch.nn.utils.clip_grad_value_(model, torch.quantile(grad.detach().abs(), 0.98))\n",
    "    # Apply source illumination to the gradient\n",
    "    grad = grad / SI\n",
    "    # grad = grad / SI\n",
    "    if iteration == 0: gmax0 =  torch.abs(grad.detach()).max()\n",
    "    # Normalize the gradient, mask it around the sources and apply taperinn to the shallower and deeper parts\n",
    "    grad = (grad /gmax0) * mask\n",
    "    gradients.append(grad.cpu().detach().numpy())\n",
    "    # Compute dm1 with the gradient as the perturbation\n",
    "    dm1 = grad.detach().clone().to(device)\n",
    "    dm1.requires_grad = True\n",
    "    dm1 = fwi.compute_dm1(params, model_velocity.detach().clone(), dm1 , loss_fn, tsamples, device)\n",
    "    # Apply source illumination to dm1\n",
    "    dm1 = dm1 / SI\n",
    "    # dm1 = dm1 / SI\n",
    "    if iteration == 0: dm1max0 =  1e1 * torch.abs(dm1.detach()).max()\n",
    "    # Normalize dm1 and mask it around the sources\n",
    "    dm1 = (dm1 / dm1max0)  * mask\n",
    "    dm1s.append(dm1.cpu().detach().numpy())\n",
    "    # Train the network\n",
    "    training_pair = {'x': dm1.clone().unsqueeze(0).unsqueeze(0),\n",
    "                    'y': grad.clone().unsqueeze(0).unsqueeze(0)}\n",
    "    network_iter = network_iter_init if iteration == 0 else network_iter_fin\n",
    "    lossn = train(network, training_pair, optimizer_unet, l2_norm, network_iter, use_scheduler=True, device=device)\n",
    "    network_loss.extend(lossn)\n",
    "    # Get the gradient from the network\n",
    "    with torch.no_grad():\n",
    "        g = network(training_pair['x']).squeeze() * mask\n",
    "    gradients_pred.append(g.cpu().detach().numpy())\n",
    "    # Get dm from the network\n",
    "    with torch.no_grad():\n",
    "        dm = network(training_pair['y']).squeeze() * mask\n",
    "    dms.append(dm.cpu().detach().numpy())\n",
    "    # Update the model\n",
    "    # if iteration > 0:\n",
    "    #     delta_model = model.detach().clone() - previous_model\n",
    "    #     delta_grad = grad.detach().clone() - previous_grad\n",
    "    #     alpha = fwi.bb_step(delta_model, delta_grad, 'short')\n",
    "    #     alphas.append(alpha)\n",
    "    #     print(f\"[iter {iteration}] lr_old = {optimizer.param_groups[-1]['lr']}\")\n",
    "    #     optimizer.param_groups[-1]['lr'] = alpha\n",
    "    #     print(f\"[iter {iteration}] lr_new = {optimizer.param_groups[-1]['lr']}\")\n",
    "    # # Save the current solution and gradient for calculating the step size in the next iteration\n",
    "    # previous_model = model.detach().clone()\n",
    "    # previous_grad = grad.detach().clone()\n",
    "    model.grad.data[:] = dm.detach().clone()\n",
    "    optimizer.step()\n",
    "    updates.append(model.detach().clone().cpu().numpy())\n",
    "    # Plot the results\n",
    "    show_one_iter_dm(grad.cpu(), dm1.cpu(), g.cpu(), dm.cpu(), model.detach().cpu(), lossn, iteration=iteration,\n",
    "                cmap='bwr', vmin=m_vmin, vmax=m_vmax, extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0), save_path=f'{exp_name}')\n",
    "t_end = time.time()\n",
    "t_delta = t_end - t_start\n",
    "print(f'Runtime:{datetime.timedelta(seconds=t_delta)}')\n",
    "# Save the results\n",
    "np.savez(f'{output_path}/losses', fwi_loss=np.array(fwi_loss),\n",
    "                               network_loss=np.array(network_loss),\n",
    "                               ssim=np.array(ssim_list),\n",
    "                               )\n",
    "np.savez(f'{output_path}/results', updates=np.array(updates), \n",
    "                            gradients=np.array(gradients), \n",
    "                            dm1s=np.array(dm1s),\n",
    "                            gradients_pred=np.array(gradients_pred),\n",
    "                            dms=np.array(dms),)\n",
    "# Save the network weights\n",
    "torch.save(network.state_dict(), f'{output_path}/network_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
    "axs[0].plot(fwi_loss)\n",
    "axs[0].set_title('Data Loss')\n",
    "axs[0].set_xlabel('Iteration')\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "axs[1].plot(ssim_list)\n",
    "axs[1].set_title('SSIM')\n",
    "axs[1].set_xlabel('Iteration')\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "plt.savefig(f'{exp_name}/losses.png',  bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one_iter_dm(grad.cpu(), dm1.cpu(), g.cpu(), dm.cpu(), model.detach().cpu(), lossn, iteration=FWI_iter,\n",
    "                cmap='bwr', vmin=m_vmin, vmax=m_vmax, extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model(updates[0], cmap='jet', vmin=m_vmin, vmax=m_vmax, figsize=(12, 5), extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0),\n",
    "           title='First update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model(updates[-1], cmap='gray', vmin=m_vmin, vmax=m_vmax, figsize=(12, 5), extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0),\n",
    "           title='Last update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vmin, v_vmax = np.percentile(model.cpu().detach().numpy(), [2,98]) \n",
    "m_vmin, m_vmax = np.percentile(model_sclar, [2,98]) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 model_true 和 model_pred 都是 numpy 数组\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 第一个子图：model_true\n",
    "im1 = ax[0].imshow(model.cpu().detach().numpy(), cmap='gray', vmin=m_vmin, vmax=m_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[0].set_title('Marmousi true model')\n",
    "fig.colorbar(im1, ax=ax[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# 第二个子图：model_pred （如果你有另一个模型）\n",
    "im2 = ax[1].imshow(model_sclar, cmap='gray', vmin=m_vmin, vmax=m_vmax,\n",
    "                   extent=(0, par['nx']*par['dx']*1000, par['nz']*par['dx']*1000, 0))\n",
    "ax[1].set_title('Predicted model')\n",
    "fig.colorbar(im2, ax=ax[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepinvhessian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
